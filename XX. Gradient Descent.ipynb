{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XX. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Data Science from Scratch (pdf)](http://math.ecnu.edu.cn/~lfzhou/seminar/[Joel_Grus]_Data_Science_from_Scratch_First_Princ.pdf#page=144)<br/>\n",
    "[An Intuitive Introduction to Gradient Descent](https://towardsdatascience.com/machine-learning-101-an-intuitive-introduction-to-gradient-descent-366b77b52645)<br/>\n",
    "[Mathematical Functions](https://www.mathsisfun.com/sets/function.html)<br/>\n",
    "[Khan Academy: Gradient (video)](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/modal/v/gradient)<br/>\n",
    "[Introduction to Derivatives](https://www.mathsisfun.com/calculus/derivatives-introduction.html)<br/>\n",
    "[Sine, Cosine, Tangent](https://www.mathsisfun.com/sine-cosine-tangent.html)<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text & Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Descent**  \n",
    "\n",
    "Gradient descent is at the heart of most Machine Learning Algorithms since many data science problems are actually optimisation problems and one of the most popular algorithms to achieve this is the gradient descent algorithm. \n",
    "\n",
    "**Basic Concepts**  \n",
    "\n",
    "Suppose you want to climb a very tall hill. Your goal is to get to the top of the hill the fastest. You look around and you realize you have more than one path to start off. Since you are on the bottom, all of these options seem to take you somewhat closer to the summit.\n",
    "\n",
    "But you want to get to the top in the fastest way possible. So, how can you do that? How can you take a step that takes you as close as possible to the summit?\n",
    "\n",
    "Up to this point, it is not clear how to take this step. That is where the Gradient Descent Algorithm can help you can help you as it captures all the partial derivatives of a multi-variable function. In the simplest terms, the derivative is the rate of change or the slope of a function at a given point.\n",
    "\n",
    "**Derivatives**\n",
    "\n",
    "In it's simplest terms, the derivative is the rate of change or slope of the function at a given point and is simply calculated as follows:\n",
    "<br/><br/><br/>\n",
    "\n",
    "<span style=\"color:#888888\">$${\\displaystyle \\text{Slope} = {\\frac{\\text{Change in Y}}{\\text{Change in X}}} }$$</span>\n",
    "<br/>\n",
    "\n",
    "![slope](./images/slope.svg)\n",
    "\n",
    "Written properly mathematically this is:  \n",
    "\n",
    "<span style=\"color:#888888\">${\\displaystyle f(x) = {\\frac {\\Delta y} {\\Delta x} }  }$</span>\n",
    "\n",
    "Where\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:#888888\">$f(x)$ = The function to work out the slope     \n",
    "$\\Delta$ = Change in</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
