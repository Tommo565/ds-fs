{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C00. Machine Learning: Introduction to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Machine Learning in SKL & Tensorflow (pdf)](./docs/Hands.Machine.Learning.Scikit.Learn.Tensorflow.5225.pdf#page=19)<br/>\n",
    "[Machine Learning in SKL & Tensorflow (Repo)](https://github.com/ageron/handson-ml)<br/>\n",
    "[Parameters vs Hyperparameters](https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/)<br/>\n",
    "[Train/Test Split & Crossvalidation](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)<br/>\n",
    "[No Free Lunch Theorum](https://en.wikipedia.org/wiki/No_free_lunch_theorem)<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "from sklearn import linear_model\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning**\n",
    "\n",
    "Machine Learning (ML) is the art and science of programming computers to learn from data. There are a number of definitions for ML, two of which are as follows:  \n",
    "<br/><br/>\n",
    "*\"Machine Learning ios the field of study that gives computers the ability the learn without being explicitly programmed.\"*  \n",
    "Arthur Samuel 1959\n",
    "<br/><br/> <br/>\n",
    "*\"A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.\"*  \n",
    "Tom Mitchell 1997\n",
    "<br/><br/><br/>\n",
    "Some examples of everyday Machine Learning:  \n",
    "\n",
    "* Email spam filters\n",
    "* Plaigarism checkers\n",
    "* Financial fraud detection\n",
    "* Facial recognition\n",
    "* Snapchat filters  \n",
    "\n",
    "The traditional approach to solving ML problems using traditional techniques is as follows:  \n",
    "![Traditional Approach](./images/traditional-approach.png)\n",
    "\n",
    "Wheras an ML approach is as follows:\n",
    "![ML Approach](./images/ml-approach.png)\n",
    "\n",
    "To summarize, Machine Learning is great for:\n",
    "* Problems for which existing solutions require a lot of hand-tuning or long lists of rules: one Machine Learning algorithm can often simplify code and perform better.\n",
    "* Complex problems for which there is no good solution at all using a traditional approach: the best Machine Learning techniques can find a solution.\n",
    "* Fluctuating environments: a Machine Learning system can adapt to new data.\n",
    "* Getting insights about complex problems and large amounts of data.\n",
    "\n",
    "\n",
    "**Algorithms**  \n",
    "\n",
    "An algorithm is a set of rules to be followed when solving problems. In machine learning, algorithms take in data and perform calculations to find an answer. The calculations can be very simple or they can be more on the complex side. Algorithms should deliver the correct answer in the most efficient manner. What good is an algorithm if it takes longer than a human would to analyze the data? What good is it if it provides incorrect information?\n",
    "\n",
    "Machine Learning Algoritms specifically are designed to correct and modify themselves for optimum performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Systems**  \n",
    "\n",
    "There are so many different types of ML systems it's useful to classify the, in broad categories as follows:\n",
    "\n",
    "* Whether or not they are trained with Human Supervision (**Supervised**, **UnSupervised**, **semiSupervised**, **Reinforcement Learning**)\n",
    "* Whether or not they can learning incrementally on the fly (**Online Learning**, **Batch Learning**)\n",
    "* Whether they work by comparing new data points to existing data points or detect patterns in the data and build a predictive model (**Instance-Based Learning**, **Model-Based Learning**)\n",
    "\n",
    "These criteria are not exclusive and can be combined.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supervised Learning**\n",
    "\n",
    "In Supervised Learning the training data that you feed into the algoritmn includes the desired solutions. These are called **labels**. A typical supervised learning task is **classification** where is is trained with example classification (e.g. spam or not-spam emails) in order to classify new data.\n",
    "\n",
    "Another task is to predict a **target** numeric value (such as the price of a car), given a set of **predictors** (mileage, age, brand etc.). This sort of task is called **regression** and to train a regression system you need many examples of cars including both their predictors and their **labels** (the values associated with the **predictors**). In Machine Learning an **attribute** is a data type (e.g., “Mileage”), while a **feature** has several meanings depending on the context, but generally means an **attribute** plus its value (e.g., “Mileage = 15,000”). Many people use the words attribute and feature interchangeably.\n",
    "\n",
    "Note that some regression algorithms can be used for classification as well and vice versa. For example **Logistic Regression** is commonly used for classification, as it can output a value that corresponds to the probability of belonging to a given class (e.g., 20% chance of being spam).\n",
    "\n",
    "Some examples of **Supervised Learning** algorithms are as follows:\n",
    "\n",
    "* k-Nearest Neighbours\n",
    "* Linear Regression\n",
    "* Logistic Regression\n",
    "* Support Vector Machines (SVM)\n",
    "* Decision Trees and Random Forests\n",
    "* Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unsupervised Learning**  \n",
    "\n",
    "In Unsupervised Learning, the training data is unlabelled and the system tries to find patterns in the data without being taught.\n",
    "\n",
    "Some examples of **Unsupervised Learning** algorithms are as follows:\n",
    "\n",
    "* Clustering \n",
    "     * k-Means\n",
    "     * Hierarchical Cluster Anaysis (HCA)\n",
    "     * Expectation Maximisation\n",
    "    \n",
    "* Visualisation and Dimensionality Reduction\n",
    "    * Principal Component Analysis (PCA)\n",
    "    * Kernel PCA\n",
    "    * Locally-Linear Embedding (LLE)\n",
    "    * t-Distributed Stochastic Neighbour Embedding (t-SNE)\n",
    "\n",
    "* Association Rule Learning\n",
    "    * Apriori\n",
    "    * Eclat\n",
    "    \n",
    "\n",
    "**Clustering**  \n",
    "\n",
    "For example if you have a lot of data about your blog's visitos you might want to run a **Clustering** algorithm to detect groups of similar visitors. This can help split your data into categories based upon the input data.\n",
    "\n",
    "![Clustering](./images/clustering.png)\n",
    "\n",
    "**t-Distributed Stochastic Neighbour Embedding (t-SNE)**  \n",
    "\n",
    "Visualization algorithms are also good examples of unsupervised learning algorithms: you feed them a lot of complex and unlabeled data, and they output a 2D or 3D representation of your data that can easily be plotted. **t-Distributed Stochastic Neighbour Embedding (t-SNE)** is a good example of this:  \n",
    "\n",
    "![Visualisation](./images/t-SNE.png)\n",
    "\n",
    "**Dimensionality Reduction**  \n",
    "\n",
    "A related task is **Dimensionality Reduction**, in which the goal is to simplify the data without losing too much information. One way to do this is to merge several correlated features into one. For example, a car’s mileage may be very correlated with its age, so the dimensionality reduction algorithm will merge them into one feature that represents the car’s wear and tear. This is called feature extraction.\n",
    "\n",
    "![PCA](./images/pca.png)\n",
    "\n",
    "**Anomaly Detection**  \n",
    "\n",
    "Yet another important unsupervised task is **Anomaly Detection** — for example, detecting unusual credit card transactions to prevent fraud, catching manufacturing defects, or automatically removing outliers from a dataset before feeding it to another learning algorithm. The system is trained with normal instances, and when it sees a new instance it can tell whether it looks like a normal one or whether it is likely an anomaly.\n",
    "\n",
    "![Anomaly Detection](./images/anomaly-detection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semisupervised learning**  \n",
    "\n",
    "Some algorithms can deal with partially labeled training data, usually a lot of unlabeled data and a little bit of labeled data. This is called **Semisupervised learning** learning.\n",
    "\n",
    "Some photo-hosting services, such as Google Photos, are good examples of this. Once you upload all your family photos to the service, it automatically recognizes that the same person A shows up in photos 1, 5,and 11, while another person B shows up in photos 2, 5, and 7. This is the unsupervised part of the algorithm (clustering). Now all the system needs is for you to tell it who these people are. Just one label per person, 4 and it is able to name everyone in every photo, which is useful for searching photos.  \n",
    "\n",
    "![Semisupervised learningn](./images/ssl.jpg)\n",
    "\n",
    "Most semisupervised learning algorithms are combinations of unsupervised and supervised algorithms. For example, **Deep Belief Networks (DBNs)** are based on unsupervised components called **Restricted\n",
    "Boltzmann machines (RBMs)** stacked on top of one another. **RBMs** are trained sequentially in an unsupervised manner, and then the whole system is fine-tuned using supervised learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reinforcement Learning**  \n",
    "\n",
    "**Reinforcement Learning** is a very different beast. The learning system, called an **agent** in this context, can observe the environment, select and perform actions, and get rewards in return (or penalties in the form of negative rewards, as in Figure 1-12). It must then learn by itself what is the best strategy, called a policy, to get the most reward over time. A policy defines what action the agent should choose when it is in a given situation.\n",
    "\n",
    "For example, many robots implement Reinforcement Learning algorithms to learn how to walk. Additionally, DeepMind’s AlphaGo program is also a good example of Reinforcement Learning: it made the headlines\n",
    "in March 2016 when it beat the world champion Lee Sedol at the game of Go. It learned its winning policy by analyzing millions of games, and then playing many games against itself. Note that learning was\n",
    "turned off during the games against the champion; AlphaGo was just applying the policy it had learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch and Online Learning**  \n",
    "\n",
    "**Batch Learning**  \n",
    "\n",
    "Another criterion used to classify Machine Learning systems is whether or not the system can learn incrementally from a stream of incoming data. In batch learning, the system is incapable of learning incrementally: it must be trained using all the available data. This will generally take a lot of time and computing resources, so it is typically done offline. First the system is trained, and then it is launched into production and runs without learning anymore; it just applies what it has learned. This is called offline learning.  \n",
    "\n",
    "If you want a **Batch Learning** system to know about new data (such as a new type of spam), you need to train a new version of the system from scratch on the full dataset (not just the new data, but also the old data), then stop the old system and replace it with the new one.\n",
    "\n",
    "**Online Learning**  \n",
    "\n",
    "In **Online Learning**, you train the system incrementally by feeding it data instances sequentially, either individually or by small groups called mini-batches. Each learning step is fast and cheap, so the system can learn about new data on the fly, as it arrives (see Figure 1-13).\n",
    "\n",
    "![Online Learning](./images/online-learning.png)\n",
    "\n",
    "One important parameter of online learning systems is how fast they should adapt to changing data: this is called the learning rate. If you set a high learning rate, then your system will rapidly adapt to new data, but it will also tend to quickly forget the old data (you don’t want a spam filter to flag only the latest kinds of spam it was shown). Conversely, if you set a low learning rate, the system will have more inertia; that is, it will learn more slowly, but it will also be less sensitive to noise in the new data or to sequences of nonrepresentative data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instance-Based Learning & Model-Based Learning** \n",
    "\n",
    "One more way to categorize Machine Learning systems is by how they generalize. Most Machine Learning tasks are about making predictions. This means that given a number of training examples, the\n",
    "system needs to be able to generalize to examples it has never seen before. Having a good performance measure on the training data is good, but insufficient; the true goal is to perform well on new instances. There are two main approaches to generalization: **Instance-based Learning** and **Model-based Learning**.  \n",
    "\n",
    "**Instance-based learning**  \n",
    "Possibly the most trivial form of learning is simply to learn by heart. If you were to create a spam filter this way, it would just flag all emails that are identical to emails that have already been flagged by users — not the worst solution, but certainly not the best. Instead of just flagging emails that are identical to known spam emails, your spam filter could be programmed to also flag emails that are very similar to known spam emails. This requires a measure of similarity between two emails. A (very basic) similarity measure between two emails could be to count the number of words they have in common. The system would flag an email as spam if it has many words in common with a known spam email. This is called **Instance-based learning**: the system learns the examples by heart, then generalizes to new cases using a similarity measure.\n",
    "\n",
    "![Instance Based Learning](./images/instance-based-learning.png)  \n",
    "\n",
    "**Model-based learning**  \n",
    "Another way to generalize from a set of examples is to build a model of these examples, then use that model to make predictions. This is called model-based learning.\n",
    "\n",
    "![Model Based Learning](./images/model-based-learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection**  \n",
    "\n",
    "For example, suppose you want to know if money makes people happy, so you download the Better Life Index data from the OECD’s website as well as stats about GDP per capita from the IMF’s website and plot a graph of the data:\n",
    "\n",
    "![GDP per capita](./images/gdp-per-capita.png)  \n",
    "\n",
    "There does seem to be a trend here! Although the data is noisy (i.e., partly random), it looks like life satisfaction goes up more or less linearly as the country’s GDP per capita increases. So you decide to model life satisfaction as a linear function of GDP per capita. This step is called model selection: you selected a linear model of life satisfaction with just one attribute, GDP per capita:  \n",
    "\n",
    "<span style=\"color:#888888\">${\\displaystyle ls = \\theta _1 + \\theta _2 \\times GDPpc }$</span>\n",
    "\n",
    "Where:\n",
    "\n",
    "<span style=\"color:#888888\">$ls$ = Life Satisfaction (our **target**)</span>  \n",
    "<span style=\"color:#888888\">$\\theta _1$ = Paremeter 1</span>  \n",
    "<span style=\"color:#888888\">$\\theta _2$ = Parameter 2</span>  \n",
    "<span style=\"color:#888888\">$GDPpc$ = GDP per Capita</span>\n",
    "\n",
    "By tweaking these parameters, you can make your model represent any linear function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load & clean the data\n",
    "df = pd.read_csv(\"./data/gdp.csv\")\n",
    "df = df.dropna(subset = ['unemployment_%'])\n",
    "df = df[df['unemployment_%'] != 'n/a']\n",
    "df['gdp_per_capita'] = df['gdp_per_capita'].str.replace(',', '')\n",
    "df['gdp_per_capita'] = pd.to_numeric(df['gdp_per_capita'], errors='coerce')\n",
    "df['unemployment_%'] = pd.to_numeric(df['unemployment_%'], errors='coerce')\n",
    "\n",
    "# Visualize the data\n",
    "df.plot(kind='scatter', x=\"gdp_per_capita\", y='unemployment_%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preparing the data for the model\n",
    "x = np.c_[df[\"gdp_per_capita\"]]\n",
    "y = np.c_[df[\"unemployment_%\"]]\n",
    "\n",
    "# Select a linear model & fit the data\n",
    "lin_reg_model = linear_model.LinearRegression()\n",
    "lin_reg_model.fit(x, y)\n",
    "\n",
    "# Make a prediction\n",
    "X_new = [[22587]] \n",
    "print(lin_reg_model.predict(X_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bad Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes a lot of data for most Machine Learning algorithms to work properly. Even for very simple problems you typically need thousands of examples, and for complex problems such as image or speech recognition you may need millions of examples (unless you can reuse parts of an existing model).\n",
    "\n",
    "In a famous paper published in 2001, entitled [The Unreasonable Effectiveness of Data](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf) Microsoft researchers Michele Banko and Eric Brillshowed that very different Machine Learning algorithms, including fairly simple ones, performed almost identically well on a complex problem of natural language disambiguation once they were given enough data.\n",
    "\n",
    "**Nonrepresentative Data**\n",
    "\n",
    "In order to generalize well, it is crucial that your training data be representative of the new cases you want to generalize to. This is true whether you use instance-based learning or model-based learning.\n",
    "\n",
    "It is crucial to use a training set that is representative of the cases you want to generalize to. This is often harder than it sounds: if the sample is too small, you will have sampling noise (i.e., nonrepresentative data as a result of chance), but even very large samples can be nonrepresentative if the sampling method is flawed. This is called **sampling bias**.\n",
    "\n",
    "**Poor-Quality Data**   \n",
    "\n",
    "Obviously, if your training data is full of errors, outliers, and noise (e.g., due to poor-quality measurements), it will make it harder for the system to detect the underlying patterns, so your system is\n",
    "less likely to perform well. It is often well worth the effort to spend time cleaning up your training data. The truth is, most data scientists spend a significant part of their time doing just that. For example: \n",
    "* If some instances are clearly outliers, it may help to simply discard them or try to fix the errors manually.\n",
    "* If some instances are missing a few features (e.g., 5% of your customers did not specify their age), you must decide whether you want to ignore this attribute altogether, ignore these instances, fill in the missing values (e.g., with the median age), or train one model with the feature and one model without it, and so on.\n",
    "\n",
    "**Irrelevant Features**  \n",
    "\n",
    "As the saying goes: garbage in, garbage out. Your system will only be capable of learning if the training data contains enough relevant features and not too many irrelevant ones. A critical part of the success of a Machine Learning project is coming up with a good set of features to train on. This process, called **feature engineering**, involves:\n",
    "* Feature selection: selecting the most useful features to train on among existing features.\n",
    "* Feature extraction: combining existing features to produce a more useful one (as we saw earlier, dimensionality reduction algorithms can help).\n",
    "* Creating new features by gathering new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bad Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting**  \n",
    "\n",
    "Overgeneralizing is something that we humans do all too often, and unfortunately machines can fall into the same trap if we are not careful. In Machine Learning this is called **Overfitting**. This means that the model performs well on the training data, but it does not **generalize** well.\n",
    "\n",
    "Complex models such as deep neural networks can detect subtle patterns in the data, but if the training set is noisy, or if it is too small (which introduces sampling noise), then the model is likely to detect patterns in the noise itself. Obviously these patterns will not **generalize** to new instances. \n",
    "\n",
    "Constraining a model to make it simpler and reduce the risk of overfitting is called **Regularization**.  For example, the linear model we defined earlier has two parameters, $\\theta _0$ and $\\theta _1$. This gives the learning algorithm two **degrees of freedom** to adapt the model to the training data: it can tweak both the height ($\\theta _0$) and the slope ($\\theta _1$) of the line. If we forced $\\theta _1$ = 0, the algorithm would have only one degree of freedom and would have a much harder time fitting the data properly: all it could do is move the line up or down to get as close as possible to the training instances, so it would end up around the mean. A very simple model indeed!  \n",
    "\n",
    "If we allow the algorithm to modify $\\theta _1$ but we force it to keep it small, then the learning algorithm will effectively have somewhere in between one and two degrees of freedom. It will produce a simpler model than with two degrees of freedom, but more complex than with just one. You want to find the right balance between fitting the data perfectly and keeping the model simple enough to ensure that it will generalize well.\n",
    "\n",
    "![Regularisation](./images/regularisation.png) \n",
    "\n",
    "The amount of regularization to apply during learning can be controlled by a **Hyperparameter**. A hyperparameter is a parameter of a learning algorithm (not of the model). As such, it is not affected by the learning algorithm itself; it must be set prior to training and remains constant during training. If you set the regularization hyperparameter to a very large value, you will get an almost flat model (a slope close to zero); the learning algorithm will almost certainly not overfit the training data, but it will be less likely to find a good solution. Tuning hyperparameters is an important part of building a Machine Learning system (you will see a detailed example in the next chapter)\n",
    "\n",
    "**Underfitting**  \n",
    "\n",
    "As you might guess, underfitting is the opposite of overfitting: it occurs when your model is too simple to learn the underlying structure of the data. For example, a linear model of life satisfaction is prone to underfit; reality is just more complex than the model, so its predictions are bound to be inaccurate, even on the training examples.  \n",
    "\n",
    "The main options to fix this problem are:\n",
    "* Selecting a more powerful model, with more parameters\n",
    "* Feeding better features to the learning algorithm (feature engineering)\n",
    "* Reducing the constraints on the model (e.g., reducing the regularization hyperparameter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing & Validating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only way to know how well a model will generalize to new cases is to actually try it out on new cases. One way to do that is to put your model in production and monitor how well it performs. This\n",
    "works well, but if your model is horribly bad, your users will complain — not the best idea.\n",
    "\n",
    "A better option is to split your data into two sets: the training set and the test set. This is called the **Train/Test Split** As these names imply, you train your model using the training set, and you test it using the test set. The error rate on new cases is called the **Generalization Error** (or out-of-sample error), and by evaluating your model on the test set, you get an estimation of this error. This value tells you how well your model will perform on instances it has never seen before.\n",
    "\n",
    "If the training error is low (i.e., your model makes few mistakes on the training set) but the generalization error is high, it means that your model is overfitting the training data.  \n",
    "\n",
    "It is common to use 80% of the data for training and hold out 20% for testing.  \n",
    "\n",
    "So evaluating a model is simple enough: just use a test set. Now suppose you are hesitating between two models (say a linear model and a polynomial model): how can you decide? One option is to train both\n",
    "and compare how well they generalize using the test set.  \n",
    "\n",
    "Now suppose that the linear model generalizes better, but you want to apply some regularization to avoid overfitting. The question is: how do you choose the value of the regularization hyperparameter? One\n",
    "option is to train 100 different models using 100 different values for this hyperparameter. Suppose you find the best hyperparameter value that produces a model with the lowest generalization error, say just 5% error.  \n",
    "\n",
    "So you launch this model into production, but unfortunately it does not perform as well as expected and produces 15% errors. What just happened? The problem is that you measured the generalization error multiple times on the test set, and you adapted the model and hyperparameters to produce the best model for that set. This means that the model is unlikely to perform as well on new data.  \n",
    "\n",
    "A common solution to this problem is to have a second holdout set called the validation set. You train multiple models with various hyperparameters using the training set, you select the model and\n",
    "hyperparameters that perform best on the validation set, and when you’re happy with your model you run a single final test against the test set to get an estimate of the generalization error.\n",
    "\n",
    "To avoid “wasting” too much training data in validation sets, a common technique is to use crossvalidation. This is where the training set is split into complementary subsets, and each model is trained against a different combination of these subsets and validated against the remaining parts. Once the model type and hyperparameters have been selected, a final model is trained using these hyperparameters on the full training set, and the generalized error is measured on the test set.\n",
    "\n",
    "A model is a simplified version of the observations. The simplifications are meant to discard the superfluous details that are unlikely to generalize to new instances. However, to decide what data to discard and what data to keep, you must make assumptions. For example, a linear model makes the assumption that the data is fundamentally linear and that the distance between the instances and the straight line is just noise, which can safely be ignored.  \n",
    "\n",
    "In a famous 1996 paper, 11 David Wolpert demonstrated that if you make absolutely no assumption about the data, then there is no reason to prefer one model over any other. This is called the No Free Lunch (NFL) theorem. For some datasets the best model is a linear model, while for other datasets it is a neural network. There is no model that is a priori guaranteed to work better (hence the name of\n",
    "the theorem). The only way to know for sure which model is best is to evaluate them all. Since this is not possible, in practice you make some reasonable assumptions about the data and you evaluate only a few reasonable models. For example, for simple tasks you may evaluate linear models with various levels of regularization, and for a complex problem you may evaluate various neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
