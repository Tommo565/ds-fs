{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Data Science from Scratch (pdf)](http://math.ecnu.edu.cn/~lfzhou/seminar/[Joel_Grus]_Data_Science_from_Scratch_First_Princ.pdf#page=112)<br/>\n",
    "[How to Read Mathematical Formulae (video)](https://www.youtube.com/watch?v=-mu3TYZ_udM)<br/>\n",
    "[Probability Models](http://www.stat.yale.edu/Courses/1997-98/101/probint.htm#)<br/>\n",
    "[Bayesian Statistics Explained](https://www.analyticsvidhya.com/blog/2016/06/bayesian-statistics-beginners-simple-english/)<br/>\n",
    "[Bayes Theorum (Wikipeida)](https://en.wikipedia.org/wiki/Bayes%27_theorem)<br/>\n",
    "[Bayes Theorum](http://www.kevinboone.net/bayes.html)<br/>\n",
    "[Bayes in Python](http://dataconomy.com/2015/02/introduction-to-bayes-theorem-with-python/)<br/>\n",
    "[Random Variables](http://www.stat.yale.edu/Courses/1997-98/101/ranvar.htm)<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text & Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probability**  \n",
    "\n",
    "Probability is a way of quantifying the uncertainty associated with events chosen from a some universe of events. Rather than getting technical about what these terms mean, think of rolling a die. The universe consists of all possible outcomes. And any subset of these outcomes is an event; for example, “the die rolls a one” or “the die rolls an even number.” Probability is expressed mathematically as follows:\n",
    "\n",
    "<span style=\"color:#888888\">${\\displaystyle P(E)}$</span>\n",
    "\n",
    "**Dependence & Independence**  \n",
    "\n",
    "Roughly speaking, we say that two events A and B are dependent if knowing something about whether A happens gives us information about whether B happens (and vice versa). Otherwise they are independent. Mathematically, we say that two events A and B are independent if the probability that they both happen is the product of the probabilities that each one happens:\n",
    "\n",
    "<span style=\"color:#888888\">${\\displaystyle P(A,B) = P(A)P(B)}$</span>\n",
    "\n",
    "If they are not necessarily independent (and if the probability of B is not zero), then we define the probability of A “conditional on B” as:\n",
    "\n",
    "<span style=\"color:#888888\">${\\displaystyle P(A,B) = P(A|B) P(B) }$</span>\n",
    "\n",
    "Where:  \n",
    "<span style=\"color:#888888\">\n",
    "$P$ = Probability  \n",
    "$A$ = Event $A$  \n",
    "$B$ = Event $B$  \n",
    "$|$ = Given that  \n",
    "$P(A,B)$ = Probability of event ${A}$ and ${B}$ occuring  \n",
    "<span style=\"color:#888888\">${\\displaystyle  P(A|B)}$ = Probability of Event ${A}$ happening, given that ${B}$ also happens</span>   \n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of drawing an ace from a deck of 52 cards \n",
    "one_ace = round(4 / 52,2)\n",
    "print('One ace = {}%'.format(one_ace*100))\n",
    "\n",
    "# Probability of drawing 2 aces from a deck of 52 cards (Dependent)\n",
    "two_aces = round(4 / 52,2) * round(3 / 51, 2)\n",
    "print('Two aces = {}%'.format(two_aces*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayes's Theorum**\n",
    "\n",
    "In order to understand Bayes Theorum we must first understand the difference between Frequentist and Bayesian Statistics.\n",
    "\n",
    "**Frequentist Statistics**\n",
    "\n",
    "Frequentist Statistics tests whether an event (hypothesis) occurs or not. It calculates the probability of an event in the long run of the experiment (i.e the experiment is repeated under the same conditions to obtain the outcome).\n",
    "\n",
    "Here, the sampling distributions of fixed size are taken. Then, the experiment is theoretically repeated infinite number of times but practically done with a stopping intention. For example, I perform an experiment with a stopping intention in mind that I will stop the experiment when it is repeated 1000 times or I see minimum 300 heads in a coin toss.\n",
    "\n",
    "Now, we’ll understand frequentist statistics using an example of coin toss. The objective is to estimate the fairness of the coin. Below is a table representing the frequency of heads:\n",
    "\n",
    "| Tosses | Heads | Difference |\n",
    "|--------|-------|------------|\n",
    "| 10     | 4     | -1         |\n",
    "| 50     | 25    | 0          |\n",
    "| 100    | 44    | -6         |\n",
    "| 500    | 255   | 5          |\n",
    "| 1000   | 502   | 2          |\n",
    "| 5000   | 2533  | 33         |\n",
    "| 10000  | 5067  | 67         |\n",
    "\n",
    "We know that probability of getting a head on tossing a fair coin is 0.5. `Heads` represents the actual number of heads obtained. `Difference` is the difference between 0.5*(No. of tosses) - no. of heads.\n",
    "\n",
    "An important thing is to note that, though the difference between the actual number of heads and expected number of heads( 50% of number of tosses) increases as the number of tosses are increased, the proportion of number of heads to total number of tosses approaches 0.5 (for a fair coin).\n",
    "\n",
    "**This experiment presents us with a very common flaw found in frequentist approach i.e. Dependence of the result of an experiment on the number of times the experiment is repeated.**\n",
    "\n",
    "The 20th century saw a massive upsurge in the frequentist statistics being applied to numerical models to check whether one sample is different from the other, a parameter is important enough to be kept in the model and various other  manifestations of hypothesis testing. But frequentist statistics suffered some great flaws in its design and interpretation which posed a serious concern in all real life problems. For example:\n",
    "\n",
    "1. p-values measured against a sample (fixed size) statistic with some stopping intention changes with change in intention and sample size. i.e If two persons work on the same data and have different stopping intention, they may get two different  p- values for the same data, which is undesirable. \n",
    "For example: Person A may choose to stop tossing a coin when the total count reaches 100 while B stops at 1000. For different sample sizes, we get different [t-scores](http://www.statisticshowto.com/probability-and-statistics/t-distribution/t-score-formula/) and different p-values (Calculated probability). Similarly, intention to stop may change from fixed number of flips to total duration of flipping. In this case too, we are bound to get different p-values.  \n",
    "<br/><br/>\n",
    "2. [The Confidence Interval](https://www.mathsisfun.com/data/confidence-interval.html) like the p-value depends heavily on the sample size. This makes the stopping potential absolutely absurd since no matter how many persons perform the tests on the same data, the results should be consistent.\n",
    "<br/><br/>\n",
    "3. Confidence Intervals are not probability distributions therefore they do not provide the most probable value for a parameter and the most probable values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayesian Statistics**<br/> \n",
    "*“Bayesian statistics is a mathematical procedure that applies probabilities to statistical problems. It provides people the tools to update their beliefs in the evidence of new data.”*\n",
    "\n",
    "Suppose, out of all the 4 championship races (F1) between Niki Lauda and James Hunt, Niki won 4 times while James managed only 1. So, if you were to bet on the winner of next race, who would he be? \n",
    "I bet you would say Niki Lauda. Here’s the twist. What if you are told that it rained once when James won and once when Niki won and it is definite that it will rain on the next date. So, who would you bet your money on now? By intuition, it is easy to see that chances of winning for James have increased drastically. But the question is: how much? \n",
    "\n",
    "We can use Bayesian Statistics to find this out. The Bayes forumla is as follows:\n",
    "\n",
    "<span style=\"color:#888888\">${\\displaystyle  P(A|B) = {\\frac{P(B|A) P(A)}{P(B)}} }$</span>\n",
    "<br/><br/><br/>\n",
    "It can also be expressed as:\n",
    "\n",
    "<span style=\"color:#888888\">${\\displaystyle P(A|B) = { \\frac{P(B|A) P(A)} {P(B|A)P(A) + P(B \\neg A)P(\\neg A) }  } }$</span>\n",
    "<br/><br/><br/>\n",
    "Where:  \n",
    "<span style=\"color:#888888\">${\\displaystyle \\neg }$ = Doesn't happen</span>  \n",
    "<span style=\"color:#888888\">${\\displaystyle  P(A|B)}$ = Probability of Event ${A}$ happening, given that ${B}$ also happens</span>   \n",
    "<span style=\"color:#888888\">${\\displaystyle  P(B|A)}$ = Probability of Event ${B}$ happening, given that ${A}$ also happens</span>  \n",
    "<span style=\"color:#888888\">${\\displaystyle P(A)}$ = Probability of Event ${A}$ happening</span>   \n",
    "<span style=\"color:#888888\">${\\displaystyle P(B)}$ = Probability of Event ${B}$ happening</span>  \n",
    "<span style=\"color:#888888\">${\\displaystyle P(B \\neg A)}$ = Probability of Event ${B}$ happening, given that ${A}$ doesn't happen</span>  \n",
    "<span style=\"color:#888888\">${\\displaystyle P(\\neg A)}$ = Probability of Event ${A}$ not happening</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few more races have happened now, and our driver data is as follows:  \n",
    "<br/>\n",
    "\n",
    "|Driver  |Wins (wet)|Wins(dry)|\n",
    "|--------|----------|---------|\n",
    "| James  |     3    |    2    |\n",
    "| Niki   |     1    |    6    |\n",
    "<br/>\n",
    "We're going to plug this data into Bayes theorum to calculate James's chances of winning in wet conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation\n",
    "\n",
    "B_A = 0.6   # Probability of James winning in the rain (it was raining 3/5 times James won)\n",
    "A = 0.417   # Probability of James winning overall (James won 5/12 races)\n",
    "B = 0.333   # Probability of rain occuring (It rained for 4/12 races)\n",
    "\n",
    "win_chance = round((B_A * A)/B,2)\n",
    "\n",
    "print (\"James's chance of winning is {}% in wet conditions\".format(win_chance*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also in dry conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_A = 0.4   # Probability of James winning in dry conditions (it was dry 2/5 times James won)\n",
    "A = 0.417   # Probability of James winning overall (James won 5/12 races)\n",
    "B = 0.666   # Probability of dry conditions (It was dry for for 8/12 races)\n",
    "\n",
    "win_chance = round((B_A * A)/B,2)\n",
    "\n",
    "print (\"James's chance of winning is {}% in dry conditions\".format(win_chance*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more useful example might be the probability of testing positive for a disease as follows:\n",
    "\n",
    "$D|T$ = Probability of having **and** testing positive for the disease.   \n",
    "$D$ = Chance of having the disease.\n",
    "\n",
    "<span style=\"color:#888888\">${\\displaystyle P(D|T) = { \\frac{P(T|D) P(D)} {P(T|D)P(D) + P(T \\neg D)P(\\neg D) }  } }$</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_and_D = 0.99           # Chance of testing positive if you have the disease\n",
    "D = 0.0001               # Chance of having the disease.\n",
    "T_not_D = 1 - T_and_D    # Chance of testing positive and not having the disease\n",
    "not_D = 1 - D            # Chance of not having the disease\n",
    "\n",
    "top = (T_and_D)*D\n",
    "bottom = ((T_and_D)*D) + ((T_not_D) * not_D)\n",
    "D_and_T = round((top / bottom)*100,2)\n",
    "print('{}% of people who test positive have the disease'.format(D_and_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Variables**\n",
    "\n",
    "A random variable, usually written $X$, is a variable whose possible values are numerical outcomes of a random phenomenon. There are two types of random variables, discrete and continuous.  \n",
    "\n",
    "A **discrete random variable** is one which may take on only a countable number of distinct values such as 0,1,2,3,4,........ Discrete random variables are usually (but not necessarily) counts. If a random variable can take only a finite number of distinct values, then it must be discrete. Examples of discrete random variables include the number of children in a family, the Friday night attendance at a cinema, the number of patients in a doctor's surgery, the number of defective light bulbs in a box of ten.\n",
    "\n",
    "The probability distribution of a discrete random variable is a list of probabilities associated with each of its possible values. It is also sometimes called the probability function or the probability mass function.\n",
    "\n",
    "Suppose a variable X can take the values 1, 2, 3, or 4. \n",
    "The probabilities associated with each outcome are described by the following data:\n",
    "\n",
    "Outcome(X): \t1\t2\t3\t4  \n",
    "Probability:\t0.1\t0.3\t0.4\t0.2  \n",
    "\n",
    "The probability that X is equal to 2 or 3 is the sum of the two probabilities: P(X = 2 or X = 3) = P(X = 2) + P(X = 3) = 0.3 + 0.4 = 0.7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **continuous random variable** is one which takes an infinite number of possible values. Continuous random variables are usually measurements. Examples include height, weight, the amount of sugar in an orange, the time required to run a mile.\n",
    "\n",
    "A continuous random variable is not defined at specific values. Instead, it is defined over an interval of values, and is represented by the area under a curve (in advanced mathematics, this is known as an integral). The probability of observing any single value is equal to 0, since the number of values which may be assumed by the random variable is infinite.\n",
    "\n",
    "Suppose a random variable X may take all values over an interval of real numbers. Then the probability that X is in the set of outcomes A, P(A), is defined to be the area above A and under a curve. The curve, which represents a function p(x), must satisfy the following:\n",
    "\n",
    "1: The curve has no negative values (p(x) > 0 for all x)\n",
    "2: The total area under the curve is equal to 1.\n",
    "A curve meeting these requirements is known as a density curve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
